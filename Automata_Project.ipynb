{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Classification dataset 1: MNIST\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_set = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Define Neural Network\n",
        "class PrunableNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrunableNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "        # Initialize binary masks for pruning\n",
        "        self.masks = {\n",
        "            \"fc1\": torch.ones_like(self.fc1.weight),\n",
        "            \"fc2\": torch.ones_like(self.fc2.weight),\n",
        "            \"fc3\": torch.ones_like(self.fc3.weight),\n",
        "        }\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))  # Apply weight masks during computation\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def apply_pruning(self):\n",
        "        \"\"\"Apply pruning by setting weights to zero based on masks.\"\"\"\n",
        "        self.fc1.weight.data *= self.masks[\"fc1\"]\n",
        "        self.fc2.weight.data *= self.masks[\"fc2\"]\n",
        "        self.fc3.weight.data *= self.masks[\"fc3\"]\n",
        "\n",
        "    def count_connections(self):\n",
        "        \"\"\"Count active connections based on binary masks.\"\"\"\n",
        "        active_connections = {\n",
        "            \"fc1\": torch.sum(self.masks[\"fc1\"]),\n",
        "            \"fc2\": torch.sum(self.masks[\"fc2\"]),\n",
        "            \"fc3\": torch.sum(self.masks[\"fc3\"]),\n",
        "        }\n",
        "        return active_connections\n",
        "\n",
        "# Pruning Logic\n",
        "class AutomataPruner:\n",
        "    def __init__(self, weights, mask, threshold=0.01, memory_depth=5):\n",
        "        self.weights = weights\n",
        "        self.mask = mask\n",
        "        self.threshold = threshold\n",
        "        self.memory_depth = memory_depth\n",
        "        self.states = np.zeros(weights.shape, dtype=int)\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"Automaton updates the pruning decisions.\"\"\"\n",
        "        for index in np.ndindex(self.weights.shape):\n",
        "            if abs(self.weights[index]) < self.threshold:\n",
        "                self.states[index] += 1\n",
        "                if self.states[index] >= self.memory_depth:\n",
        "                    self.mask[index] = 0  # Prune\n",
        "            else:\n",
        "                self.states[index] = max(self.states[index] - 1, 0)  # Reward\n",
        "\n",
        "# Model Summary\n",
        "def model_summary(model, input_size):\n",
        "    def register_hook(module):\n",
        "        def hook(module, inputs, outputs):\n",
        "            class_name = module.__class__.__name__\n",
        "            module_idx = len(summary)\n",
        "            m_key = f\"{class_name}-{module_idx + 1}\"\n",
        "            summary[m_key] = {\n",
        "                \"input_shape\": list(inputs[0].size()),\n",
        "                \"output_shape\": list(outputs.size()),\n",
        "                \"num_params\": sum(p.numel() for p in module.parameters() if p.requires_grad),\n",
        "            }\n",
        "\n",
        "        if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList) and module != model:\n",
        "            hooks.append(module.register_forward_hook(hook))\n",
        "\n",
        "    summary = {}\n",
        "    hooks = []\n",
        "    model.apply(register_hook)\n",
        "    with torch.no_grad():\n",
        "        model(torch.zeros(1, *input_size))\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    print(\"Model Summary\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"{'Layer':<30} {'Input Shape':<30} {'Output Shape':<30} {'Param #':<20}\")\n",
        "    print(\"=\" * 80)\n",
        "    total_params = 0\n",
        "    for layer, info in summary.items():\n",
        "        total_params += info[\"num_params\"]\n",
        "        print(f\"{layer:<30} {str(info['input_shape']):<30} {str(info['output_shape']):<30} {info['num_params']:<20}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "# Train and Prune\n",
        "def train_and_prune(model, train_loader, criterion, optimizer, pruners=None, epochs=10):\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if pruners:  # Update pruners if pruning is enabled\n",
        "            with torch.no_grad():\n",
        "                for pruner in pruners:\n",
        "                    pruner.update()\n",
        "            model.apply_pruning()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    return training_time\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    input_size = (1, 28, 28)\n",
        "\n",
        "    # Unpruned Model\n",
        "    model_without_pruning = PrunableNet()\n",
        "    print(\"\\nUnpruned Model Summary:\")\n",
        "    params_no_pruning = model_summary(model_without_pruning, input_size)\n",
        "\n",
        "    optimizer = optim.SGD(model_without_pruning.parameters(), lr=0.01, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    print(\"\\nTraining without pruning...\")\n",
        "    time_no_pruning = train_and_prune(model_without_pruning, train_loader, criterion, optimizer)\n",
        "    acc_no_pruning = evaluate(model_without_pruning, test_loader)\n",
        "\n",
        "    # Pruned Model\n",
        "    pruned_model = PrunableNet()\n",
        "    print(\"\\nPruned Model Summary:\")\n",
        "    params_with_pruning = model_summary(pruned_model, input_size)\n",
        "\n",
        "    optimizer = optim.SGD(pruned_model.parameters(), lr=0.01, momentum=0.9)\n",
        "    pruners = [\n",
        "        AutomataPruner(pruned_model.fc1.weight.data.numpy(), pruned_model.masks[\"fc1\"]),\n",
        "        AutomataPruner(pruned_model.fc2.weight.data.numpy(), pruned_model.masks[\"fc2\"]),\n",
        "        AutomataPruner(pruned_model.fc3.weight.data.numpy(), pruned_model.masks[\"fc3\"]),\n",
        "    ]\n",
        "    print(\"\\nTraining with pruning...\")\n",
        "    time_with_pruning = train_and_prune(pruned_model, train_loader, criterion, optimizer, pruners)\n",
        "    acc_with_pruning = evaluate(pruned_model, test_loader)\n",
        "\n",
        "    # Count active connections (weights)\n",
        "    connections_no_pruning = sum(p.numel() for p in model_without_pruning.parameters() if p.requires_grad)\n",
        "    active_connections_with_pruning = pruned_model.count_connections()\n",
        "\n",
        "    print(\"\\nComparison Report\")\n",
        "    print(f\"Training Time (No Pruning): {time_no_pruning:.2f} seconds\")\n",
        "    print(f\"Training Time (With Pruning): {time_with_pruning:.2f} seconds\")\n",
        "    print(f\"Accuracy (No Pruning): {acc_no_pruning * 100:.2f}%\")\n",
        "    print(f\"Accuracy (With Pruning): {acc_with_pruning * 100:.2f}%\")\n",
        "    print(f\"Active Connections (No Pruning): {connections_no_pruning}\")\n",
        "    print(f\"Active Connections (With Pruning):\")\n",
        "    print(f\"  fc1: {active_connections_with_pruning['fc1']}\")\n",
        "    print(f\"  fc2: {active_connections_with_pruning['fc2']}\")\n",
        "    print(f\"  fc3: {active_connections_with_pruning['fc3']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAscx96DsRCB",
        "outputId": "74470ccc-e500-4e1d-cde0-00ae867fb9f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unpruned Model Summary:\n",
            "Model Summary\n",
            "================================================================================\n",
            "Layer                          Input Shape                    Output Shape                   Param #             \n",
            "================================================================================\n",
            "Linear-1                       [1, 784]                       [1, 512]                       401920              \n",
            "Linear-2                       [1, 512]                       [1, 256]                       131328              \n",
            "Linear-3                       [1, 256]                       [1, 10]                        2570                \n",
            "================================================================================\n",
            "Total Parameters: 535818\n",
            "\n",
            "Training without pruning...\n",
            "Epoch 1/10, Loss: 0.16198521852493286\n",
            "Epoch 2/10, Loss: 0.11243375390768051\n",
            "Epoch 3/10, Loss: 0.1772448718547821\n",
            "Epoch 4/10, Loss: 0.04708769917488098\n",
            "Epoch 5/10, Loss: 0.047526564449071884\n",
            "Epoch 6/10, Loss: 0.03601180389523506\n",
            "Epoch 7/10, Loss: 0.0051420629024505615\n",
            "Epoch 8/10, Loss: 0.14726479351520538\n",
            "Epoch 9/10, Loss: 0.0082174614071846\n",
            "Epoch 10/10, Loss: 0.08859815448522568\n",
            "Accuracy: 97.81%\n",
            "\n",
            "Pruned Model Summary:\n",
            "Model Summary\n",
            "================================================================================\n",
            "Layer                          Input Shape                    Output Shape                   Param #             \n",
            "================================================================================\n",
            "Linear-1                       [1, 784]                       [1, 512]                       401920              \n",
            "Linear-2                       [1, 512]                       [1, 256]                       131328              \n",
            "Linear-3                       [1, 256]                       [1, 10]                        2570                \n",
            "================================================================================\n",
            "Total Parameters: 535818\n",
            "\n",
            "Training with pruning...\n",
            "Epoch 1/10, Loss: 0.16674521565437317\n",
            "Epoch 2/10, Loss: 0.03568703308701515\n",
            "Epoch 3/10, Loss: 0.045092541724443436\n",
            "Epoch 4/10, Loss: 0.11985532194375992\n",
            "Epoch 5/10, Loss: 0.008759601041674614\n",
            "Epoch 6/10, Loss: 0.1931411474943161\n",
            "Epoch 7/10, Loss: 0.11026925593614578\n",
            "Epoch 8/10, Loss: 0.020516136661171913\n",
            "Epoch 9/10, Loss: 0.07580753415822983\n",
            "Epoch 10/10, Loss: 0.08800404518842697\n",
            "Accuracy: 98.35%\n",
            "\n",
            "Comparison Report\n",
            "Training Time (No Pruning): 142.66 seconds\n",
            "Training Time (With Pruning): 161.78 seconds\n",
            "Accuracy (No Pruning): 97.81%\n",
            "Accuracy (With Pruning): 98.35%\n",
            "Active Connections (No Pruning): 535818\n",
            "Active Connections (With Pruning):\n",
            "  fc1: 296387.0\n",
            "  fc2: 103645.0\n",
            "  fc3: 2379.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification dataset 1: Breast Cancer\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load and prepare breast cancer dataset\n",
        "def load_breast_cancer_data(batch_size=32):\n",
        "    data = load_breast_cancer()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Convert to PyTorch datasets\n",
        "    class BreastCancerDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, X, y):\n",
        "            self.X = torch.FloatTensor(X)\n",
        "            self.y = torch.LongTensor(y)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.X)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return self.X[idx], self.y[idx]\n",
        "\n",
        "    train_set = BreastCancerDataset(X_train, y_train)\n",
        "    test_set = BreastCancerDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, X.shape[1]\n",
        "\n",
        "# Neural Network for Breast Cancer classification\n",
        "class PrunableNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(PrunableNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)  # 2 classes: malignant or benign\n",
        "\n",
        "        # Initialize binary masks for pruning\n",
        "        self.masks = {\n",
        "            \"fc1\": torch.ones_like(self.fc1.weight),\n",
        "            \"fc2\": torch.ones_like(self.fc2.weight),\n",
        "            \"fc3\": torch.ones_like(self.fc3.weight),\n",
        "        }\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def apply_pruning(self):\n",
        "        \"\"\"Apply pruning by setting weights to zero based on masks.\"\"\"\n",
        "        self.fc1.weight.data *= self.masks[\"fc1\"]\n",
        "        self.fc2.weight.data *= self.masks[\"fc2\"]\n",
        "        self.fc3.weight.data *= self.masks[\"fc3\"]\n",
        "\n",
        "    def count_connections(self):\n",
        "        \"\"\"Count active connections based on binary masks.\"\"\"\n",
        "        active_connections = {\n",
        "            \"fc1\": torch.sum(self.masks[\"fc1\"]),\n",
        "            \"fc2\": torch.sum(self.masks[\"fc2\"]),\n",
        "            \"fc3\": torch.sum(self.masks[\"fc3\"]),\n",
        "        }\n",
        "        return active_connections\n",
        "\n",
        "# Pruning Logic\n",
        "class AutomataPruner:\n",
        "    def __init__(self, weights, mask, threshold=0.01, memory_depth=5):\n",
        "        self.weights = weights\n",
        "        self.mask = mask\n",
        "        self.threshold = threshold\n",
        "        self.memory_depth = memory_depth\n",
        "        self.states = np.zeros(weights.shape, dtype=int)\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"Automaton updates the pruning decisions.\"\"\"\n",
        "        for index in np.ndindex(self.weights.shape):\n",
        "            if abs(self.weights[index]) < self.threshold:\n",
        "                self.states[index] += 1\n",
        "                if self.states[index] >= self.memory_depth:\n",
        "                    self.mask[index] = 0  # Prune\n",
        "            else:\n",
        "                self.states[index] = max(self.states[index] - 1, 0)  # Reward\n",
        "\n",
        "# Train and Prune\n",
        "def train_and_prune(model, train_loader, criterion, optimizer, pruners=None, epochs=10):\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        if pruners:  # Update pruners if pruning is enabled\n",
        "            with torch.no_grad():\n",
        "                for pruner in pruners:\n",
        "                    pruner.update()\n",
        "            model.apply_pruning()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    return training_time\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load breast cancer dataset\n",
        "    train_loader, test_loader, input_size = load_breast_cancer_data()\n",
        "    print(f\"Input features: {input_size}\")\n",
        "\n",
        "    # Train model without pruning\n",
        "    model_without_pruning = PrunableNet(input_size)\n",
        "    optimizer = optim.Adam(model_without_pruning.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"\\nTraining without pruning...\")\n",
        "    time_no_pruning = train_and_prune(model_without_pruning, train_loader, criterion, optimizer)\n",
        "    acc_no_pruning = evaluate(model_without_pruning, test_loader)\n",
        "\n",
        "    # Count connections in unpruned model\n",
        "    connections_no_pruning = sum(p.numel() for p in model_without_pruning.parameters() if p.requires_grad)\n",
        "    print(f\"Active Connections (No Pruning): {connections_no_pruning}\")\n",
        "\n",
        "    # Train model with pruning\n",
        "    model_with_pruning = PrunableNet(input_size)\n",
        "    optimizer = optim.Adam(model_with_pruning.parameters(), lr=0.001)\n",
        "\n",
        "    pruners = [\n",
        "        AutomataPruner(model_with_pruning.fc1.weight.data.numpy(), model_with_pruning.masks[\"fc1\"]),\n",
        "        AutomataPruner(model_with_pruning.fc2.weight.data.numpy(), model_with_pruning.masks[\"fc2\"]),\n",
        "        AutomataPruner(model_with_pruning.fc3.weight.data.numpy(), model_with_pruning.masks[\"fc3\"]),\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTraining with pruning...\")\n",
        "    time_with_pruning = train_and_prune(model_with_pruning, train_loader, criterion, optimizer, pruners)\n",
        "    acc_with_pruning = evaluate(model_with_pruning, test_loader)\n",
        "\n",
        "    # Count active connections in pruned model\n",
        "    active_connections_with_pruning = model_with_pruning.count_connections()\n",
        "\n",
        "    # Report results\n",
        "    print(\"\\nComparison Report\")\n",
        "    print(f\"Training Time (No Pruning): {time_no_pruning:.2f} seconds\")\n",
        "    print(f\"Training Time (With Pruning): {time_with_pruning:.2f} seconds\")\n",
        "    print(f\"Accuracy (No Pruning): {acc_no_pruning * 100:.2f}%\")\n",
        "    print(f\"Accuracy (With Pruning): {acc_with_pruning * 100:.2f}%\")\n",
        "    print(f\"Active Connections (No Pruning): {connections_no_pruning}\")\n",
        "    print(f\"Active Connections (With Pruning):\")\n",
        "    print(f\"  fc1: {active_connections_with_pruning['fc1']}\")\n",
        "    print(f\"  fc2: {active_connections_with_pruning['fc2']}\")\n",
        "    print(f\"  fc3: {active_connections_with_pruning['fc3']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzujmMWPXdgh",
        "outputId": "217a1656-192d-4c9b-ded6-2846bf74bf1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input features: 30\n",
            "\n",
            "Training without pruning...\n",
            "Epoch 1/10, Average Loss: 0.6425\n",
            "Epoch 2/10, Average Loss: 0.4882\n",
            "Epoch 3/10, Average Loss: 0.2989\n",
            "Epoch 4/10, Average Loss: 0.1628\n",
            "Epoch 5/10, Average Loss: 0.1087\n",
            "Epoch 6/10, Average Loss: 0.0869\n",
            "Epoch 7/10, Average Loss: 0.0692\n",
            "Epoch 8/10, Average Loss: 0.0599\n",
            "Epoch 9/10, Average Loss: 0.0553\n",
            "Epoch 10/10, Average Loss: 0.0525\n",
            "Accuracy: 98.25%\n",
            "Active Connections (No Pruning): 4130\n",
            "\n",
            "Training with pruning...\n",
            "Epoch 1/10, Average Loss: 0.6411\n",
            "Epoch 2/10, Average Loss: 0.4521\n",
            "Epoch 3/10, Average Loss: 0.2736\n",
            "Epoch 4/10, Average Loss: 0.1577\n",
            "Epoch 5/10, Average Loss: 0.1119\n",
            "Epoch 6/10, Average Loss: 0.0910\n",
            "Epoch 7/10, Average Loss: 0.1077\n",
            "Epoch 8/10, Average Loss: 0.0646\n",
            "Epoch 9/10, Average Loss: 0.0606\n",
            "Epoch 10/10, Average Loss: 0.0551\n",
            "Accuracy: 99.12%\n",
            "\n",
            "Comparison Report\n",
            "Training Time (No Pruning): 0.33 seconds\n",
            "Training Time (With Pruning): 0.29 seconds\n",
            "Accuracy (No Pruning): 98.25%\n",
            "Accuracy (With Pruning): 99.12%\n",
            "Active Connections (No Pruning): 4130\n",
            "Active Connections (With Pruning):\n",
            "  fc1: 1851.0\n",
            "  fc2: 1923.0\n",
            "  fc3: 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression Dataset: California Housing\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load Dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = np.expand_dims(y, axis=1)  # Make y a 2D array for PyTorch compatibility\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
        "\n",
        "# Define Neural Network for Regression\n",
        "class PrunableNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrunableNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(X.shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "        # Initialize binary masks for pruning\n",
        "        self.masks = {\n",
        "            \"fc1\": torch.ones_like(self.fc1.weight),\n",
        "            \"fc2\": torch.ones_like(self.fc2.weight),\n",
        "            \"fc3\": torch.ones_like(self.fc3.weight),\n",
        "        }\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def apply_pruning(self):\n",
        "        \"\"\"Apply pruning by setting weights to zero based on masks.\"\"\"\n",
        "        self.fc1.weight.data *= self.masks[\"fc1\"]\n",
        "        self.fc2.weight.data *= self.masks[\"fc2\"]\n",
        "        self.fc3.weight.data *= self.masks[\"fc3\"]\n",
        "\n",
        "    def count_connections(self):\n",
        "        \"\"\"Count active connections based on binary masks.\"\"\"\n",
        "        active_connections = {\n",
        "            \"fc1\": torch.sum(self.masks[\"fc1\"]),\n",
        "            \"fc2\": torch.sum(self.masks[\"fc2\"]),\n",
        "            \"fc3\": torch.sum(self.masks[\"fc3\"]),\n",
        "        }\n",
        "        return active_connections\n",
        "\n",
        "# Train and Prune\n",
        "def train_and_prune(model, train_loader, criterion, optimizer, pruners=None, epochs=10):\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if pruners:  # Update pruners if pruning is enabled\n",
        "            with torch.no_grad():\n",
        "                for pruner in pruners:\n",
        "                    pruner.update()\n",
        "            model.apply_pruning()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    return training_time\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
        "    return test_loss\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Unpruned Model\n",
        "    model_without_pruning = PrunableNet()\n",
        "    optimizer = optim.SGD(model_without_pruning.parameters(), lr=0.01, momentum=0.9)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    print(\"\\nTraining without pruning...\")\n",
        "    time_no_pruning = train_and_prune(model_without_pruning, train_loader, criterion, optimizer)\n",
        "    mse_no_pruning = evaluate(model_without_pruning, test_loader, criterion)\n",
        "\n",
        "    # Count connections in unpruned model\n",
        "    connections_no_pruning = sum(p.numel() for p in model_without_pruning.parameters() if p.requires_grad)\n",
        "    print(f\"Active Connections (No Pruning): {connections_no_pruning}\")\n",
        "\n",
        "    # Pruned Model\n",
        "    pruned_model = PrunableNet()\n",
        "    optimizer = optim.SGD(pruned_model.parameters(), lr=0.01, momentum=0.9)\n",
        "    pruners = [\n",
        "        AutomataPruner(pruned_model.fc1.weight.data.numpy(), pruned_model.masks[\"fc1\"]),\n",
        "        AutomataPruner(pruned_model.fc2.weight.data.numpy(), pruned_model.masks[\"fc2\"]),\n",
        "        AutomataPruner(pruned_model.fc3.weight.data.numpy(), pruned_model.masks[\"fc3\"]),\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTraining with pruning...\")\n",
        "    time_with_pruning = train_and_prune(pruned_model, train_loader, criterion, optimizer, pruners)\n",
        "    mse_with_pruning = evaluate(pruned_model, test_loader, criterion)\n",
        "\n",
        "    # Count active connections in pruned model\n",
        "    active_connections_with_pruning = pruned_model.count_connections()\n",
        "\n",
        "    # Report results\n",
        "    print(\"\\nComparison Report\")\n",
        "    print(f\"Training Time (No Pruning): {time_no_pruning:.2f} seconds\")\n",
        "    print(f\"Training Time (With Pruning): {time_with_pruning:.2f} seconds\")\n",
        "    print(f\"MSE (No Pruning): {mse_no_pruning:.4f}\")\n",
        "    print(f\"MSE (With Pruning): {mse_with_pruning:.4f}\")\n",
        "    print(f\"Active Connections (No Pruning): {connections_no_pruning}\")\n",
        "    print(f\"Active Connections (With Pruning):\")\n",
        "    print(f\"  fc1: {active_connections_with_pruning['fc1']}\")\n",
        "    print(f\"  fc2: {active_connections_with_pruning['fc2']}\")\n",
        "    print(f\"  fc3: {active_connections_with_pruning['fc3']}\")\n"
      ],
      "metadata": {
        "id": "etiJtCsbEK5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99fa503f-c5c8-45ec-ad16-cd4119386267"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training without pruning...\n",
            "Epoch 1/10, Loss: 0.3446616232395172\n",
            "Epoch 2/10, Loss: 0.45953094959259033\n",
            "Epoch 3/10, Loss: 0.5902723670005798\n",
            "Epoch 4/10, Loss: 0.4364682734012604\n",
            "Epoch 5/10, Loss: 0.6320103406906128\n",
            "Epoch 6/10, Loss: 0.3662148416042328\n",
            "Epoch 7/10, Loss: 0.31736329197883606\n",
            "Epoch 8/10, Loss: 0.3980819880962372\n",
            "Epoch 9/10, Loss: 0.17703774571418762\n",
            "Epoch 10/10, Loss: 0.3322415053844452\n",
            "Test Loss (MSE): 0.3181\n",
            "Active Connections (No Pruning): 9473\n",
            "\n",
            "Training with pruning...\n",
            "Epoch 1/10, Loss: 0.5458833575248718\n",
            "Epoch 2/10, Loss: 0.2958527207374573\n",
            "Epoch 3/10, Loss: 0.3071359395980835\n",
            "Epoch 4/10, Loss: 0.27384474873542786\n",
            "Epoch 5/10, Loss: 0.3515761196613312\n",
            "Epoch 6/10, Loss: 0.41151392459869385\n",
            "Epoch 7/10, Loss: 0.1601962447166443\n",
            "Epoch 8/10, Loss: 0.12301412969827652\n",
            "Epoch 9/10, Loss: 0.22080036997795105\n",
            "Epoch 10/10, Loss: 0.2222491353750229\n",
            "Test Loss (MSE): 0.3265\n",
            "\n",
            "Comparison Report\n",
            "Training Time (No Pruning): 2.72 seconds\n",
            "Training Time (With Pruning): 5.22 seconds\n",
            "MSE (No Pruning): 0.3181\n",
            "MSE (With Pruning): 0.3265\n",
            "Active Connections (No Pruning): 9473\n",
            "Active Connections (With Pruning):\n",
            "  fc1: 1006.0\n",
            "  fc2: 7416.0\n",
            "  fc3: 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install libcairo2-dev ffmpeg \\\n",
        "    texlive texlive-latex-extra texlive-fonts-extra \\\n",
        "    texlive-latex-recommended texlive-science \\\n",
        "    tipa libpango1.0-dev\n",
        "!pip install manim\n",
        "!pip install IPython==8.21.0"
      ],
      "metadata": {
        "id": "jImClAhDEJZK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from manim import *"
      ],
      "metadata": {
        "id": "PCdsaFxqFR_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from manim import *\n",
        "import numpy as np\n",
        "\n",
        "class AutomataVisualization(Scene):\n",
        "    def construct(self):\n",
        "        # Colors and styling\n",
        "        STATE_COLOR = \"#2196F3\"\n",
        "        PRUNED_COLOR = \"#FF5252\"\n",
        "        REWARD_COLOR = \"#4CAF50\"\n",
        "        THRESHOLD_COLOR = \"#FFA726\"\n",
        "\n",
        "        # Create title with reduced font size and adjusted position\n",
        "        title = Text(\"Weight Pruning Automata\", font_size=36)\n",
        "        subtitle = Text(\"Deterministic Finite Automaton for Neural Network Pruning\", font_size=20)\n",
        "        subtitle.set_color(BLUE)\n",
        "        title_group = VGroup(title, subtitle).arrange(DOWN, buff=0.2)\n",
        "        title_group.to_edge(UP, buff=0.5)\n",
        "        self.play(Write(title_group), run_time=1.5)\n",
        "\n",
        "        # Create state diagram with adjusted positioning\n",
        "        def create_state_diagram():\n",
        "            states = VGroup()\n",
        "            arrows = VGroup()\n",
        "            labels = VGroup()\n",
        "            x_positions = np.linspace(-5.5, 5.5, 6)\n",
        "\n",
        "            for i, x in enumerate(x_positions):\n",
        "                circle = Circle(radius=0.4, color=STATE_COLOR)\n",
        "                label = Text(\"M\" if i == len(x_positions)-1 else f\"S{i}\", font_size=20)\n",
        "                state = VGroup(circle, label).move_to([x, 0.5, 0])\n",
        "                states.add(state)\n",
        "\n",
        "                if i == len(x_positions)-1:\n",
        "                    circle.set_color(PRUNED_COLOR)\n",
        "                    pruning_label = Text(\"(Pruning State)\", font_size=14, color=PRUNED_COLOR)\n",
        "                    pruning_label.next_to(state, UP, buff=0.1)\n",
        "                    labels.add(pruning_label)\n",
        "\n",
        "            for i in range(len(states)-1):\n",
        "                forward = Arrow(\n",
        "                    states[i].get_right(),\n",
        "                    states[i+1].get_left(),\n",
        "                    buff=0.1,\n",
        "                    color=THRESHOLD_COLOR\n",
        "                )\n",
        "                backward = Arrow(\n",
        "                    states[i+1].get_bottom(),\n",
        "                    states[i].get_bottom(),\n",
        "                    buff=0.1,\n",
        "                    color=REWARD_COLOR,\n",
        "                    path_arc=-2\n",
        "                )\n",
        "                arrows.add(forward, backward)\n",
        "\n",
        "            return states, arrows, labels\n",
        "\n",
        "        states, arrows, labels = create_state_diagram()\n",
        "\n",
        "        # Show initial diagram\n",
        "        self.play(Create(states), run_time=2)\n",
        "        self.play(Create(arrows), run_time=2)\n",
        "        self.play(Write(labels), run_time=1.5)\n",
        "\n",
        "        # Add transition labels with reduced font size and adjusted position\n",
        "        forward_label = Text(\"|w| < threshold\", font_size=16, color=THRESHOLD_COLOR)\n",
        "        forward_label.next_to(arrows[0], UP, buff=0.2)  # Increased buffer to move label up\n",
        "        backward_label = Text(\"|w| ≥ threshold\", font_size=16, color=REWARD_COLOR)\n",
        "        backward_label.next_to(arrows[1], DOWN, buff=0.1)\n",
        "        self.play(Write(forward_label), Write(backward_label), run_time=1.5)\n",
        "\n",
        "        # Add weight value counter at bottom left with adjusted position\n",
        "        weight_counter = Variable(0.5, Text(\"Current Weight |w|\", font_size=16), var_type=DecimalNumber)\n",
        "        weight_counter.to_corner(DL).shift(RIGHT * 0.5 + UP * 0.5)\n",
        "        self.play(Write(weight_counter), run_time=1)\n",
        "\n",
        "        # Add threshold line with adjusted position to be fully visible\n",
        "        threshold_line = DashedLine(\n",
        "            start=[-6, -1.5, 0],\n",
        "            end=[5.5, -1.5, 0],  # Shortened the line to fit within the screen\n",
        "            color=THRESHOLD_COLOR,\n",
        "            dash_length=0.2\n",
        "        )\n",
        "        threshold_text = Text(\"T=0.5\", font_size=16, color=THRESHOLD_COLOR)\n",
        "        threshold_text.next_to(threshold_line, LEFT, buff=0.1)  # Moved text to the left of the line\n",
        "        self.play(Create(threshold_line), Write(threshold_text), run_time=1.5)\n",
        "\n",
        "        # Create state pointer\n",
        "        pointer = Triangle(color=YELLOW).scale(0.15).rotate(PI/2)\n",
        "        pointer.next_to(states[0], UP, buff=0.1)\n",
        "        self.play(Create(pointer), run_time=1)\n",
        "\n",
        "        # Add explanation box with reduced font size and adjusted position\n",
        "        explanation = VGroup(\n",
        "            Text(\"Automaton Rules:\", color=WHITE, font_size=18),\n",
        "            Text(\"1. If |w| < threshold: Move right\", color=THRESHOLD_COLOR, font_size=14),\n",
        "            Text(\"2. If |w| ≥ threshold: Move left\", color=REWARD_COLOR, font_size=14),\n",
        "            Text(\"3. At state M: Weight is pruned\", color=PRUNED_COLOR, font_size=14)\n",
        "        ).arrange(DOWN, aligned_edge=LEFT, buff=0.1)\n",
        "        explanation.scale(0.9).to_corner(DR).shift(LEFT * 0.5 + UP * 0.5)\n",
        "        self.play(Write(explanation), run_time=2)\n",
        "\n",
        "        # Simulate automata transitions to S4\n",
        "        weight_values = [0.8, 0.3, 0.2, 0.1, 0.05]\n",
        "        current_state = 0\n",
        "\n",
        "        for weight in weight_values:\n",
        "            self.play(\n",
        "                weight_counter.tracker.animate.set_value(weight),\n",
        "                run_time=0.8\n",
        "            )\n",
        "\n",
        "            if weight < 0.5:\n",
        "                if current_state < 4:\n",
        "                    current_state += 1\n",
        "                    self.play(\n",
        "                        pointer.animate.next_to(states[current_state], UP, buff=0.1),\n",
        "                        states[current_state][0].animate.set_color(STATE_COLOR),\n",
        "                        run_time=0.8\n",
        "                    )\n",
        "            else:\n",
        "                if current_state > 0:\n",
        "                    self.play(\n",
        "                        states[current_state][0].animate.set_color(STATE_COLOR),\n",
        "                        run_time=0.8\n",
        "                    )\n",
        "                    current_state -= 1\n",
        "                    self.play(\n",
        "                        pointer.animate.next_to(states[current_state], UP, buff=0.1),\n",
        "                        run_time=0.8\n",
        "                    )\n",
        "\n",
        "        # Special transition to state M\n",
        "        self.wait(0.5)\n",
        "\n",
        "        # Add transition message with adjusted position\n",
        "        transition_message = Text(\"Weight remains below threshold...\", color=YELLOW, font_size=18)\n",
        "        transition_message.to_edge(UP, buff=1.5)\n",
        "        self.play(Write(transition_message), run_time=1)\n",
        "        self.wait(1)\n",
        "        self.play(FadeOut(transition_message))\n",
        "\n",
        "        # Move to state M\n",
        "        self.play(\n",
        "            pointer.animate.next_to(states[5], UP, buff=0.1),\n",
        "            run_time=1.2\n",
        "        )\n",
        "\n",
        "        # Create pruning notification box with adjusted size and position\n",
        "        notification_box = VGroup(\n",
        "            Rectangle(width=3.5, height=1.5, fill_opacity=0.2, color=PRUNED_COLOR),\n",
        "            Text(\"Memory Depth Reached\", color=PRUNED_COLOR, font_size=20),\n",
        "            Text(\"Weight is Pruned\", color=PRUNED_COLOR, font_size=16)\n",
        "        )\n",
        "        notification_box[1:].arrange(DOWN, buff=0.1)\n",
        "        notification_box[1:].move_to(notification_box[0])\n",
        "        notification_box.to_edge(UP, buff=0.5)  # Moved to top of screen\n",
        "\n",
        "        # Fade out title and subtitle, then show notification box\n",
        "        self.play(\n",
        "            FadeOut(title_group),\n",
        "            FadeIn(notification_box),\n",
        "            run_time=1.5\n",
        "        )\n",
        "        self.wait(1.5)\n",
        "        self.play(FadeOut(notification_box))\n",
        "\n",
        "        # Final wait\n",
        "        self.wait(2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config.pixel_height = 1080\n",
        "    config.pixel_width = 1920\n",
        "    config.frame_rate = 60\n",
        "    with tempconfig({\"quality\": \"production_quality\", \"preview\": True}):\n",
        "        scene = AutomataVisualization()\n",
        "        scene.render()\n"
      ],
      "metadata": {
        "id": "TIi4PNvGFaND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}